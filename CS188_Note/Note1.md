# Agents

> 在AI中，目前的核心问题是创造一个理性智能体，即一个有目标或偏好，并在给定目标下，试图执行一系列可以产生最佳或最优预测结果的Action的实体。

**Rational agents**(理性智能体)存在于特定于智能体的给定实例的环境中。举个简单的例子，跳棋agent的环境是它与对手对弈的虚拟跳棋棋盘，棋子的移动就是action。环境和存在于其中的agent共同创造了一个世界。

**Reflex agents**(反射智能体)不考虑其actions可能造成的结果，而是仅根据当前状态来选择下一步的action. 这类智能体通常优于**planning agents**(规划智能体).

**Planning agent**通过维护一个世界模型，并使用该模型来模拟执行各种action。而后，agent可以确定action的假设结果，并从中选择最佳结果。从某种意义上来说，这是一种模拟的"智能"，就像人类在任何情况下试图确定最佳行动时所做的那样 —— 提前思考

为了定义任务环境，我们使用**PEAS**(Performance Measure, Environment, Actuators, Sensors - 性能度量，环境，执行器，传感器)描述。

- 性能度量描述智能体试图提高的效用(*utility*)
- 环境描述了智能体在哪行动以及影响智能体的因素
- 执行器和传感器是智能体作用于环境并从中搜集信息的途径

智能体的设计很大程度上取决于智能体所处的环境类型。我们可以通过下面的方法来描述环境的类型。

- 在**部分可观测**(partially observable)的环境中，智能体没有关于状态的全部信息，因此智能体必须对世界的状态有一个内部估计。这与**完全可观测**(fully observable)环境相对，在确定性环境中，智能体拥有关于他们所处状态的全部信息、
- **随机**的(Stochastic)环境在转移模型中有不确定性，例如：在特定的状态下采取一个行动可能会产生多个具有不同概率的可能结果。这与**确定**性(deterministic)环境相对，在确定性环境中，在某状态下采取一个行动只有一个肯定会发生的结果
- 在**多智能体**(multi-agent)环境中，智能体和其他智能体一起在环境中活动。因此，智能体可能需要随机化(*randomize*)其行为，以避免被其他智能体"预测"。
- 如果当智能体在其中活动时，环境不会发生变化，那么这样的环境就被称为**静态**的(static)。这与**动态**(dynamic)环境相对，动态环境会随着智能体与之交互而发生变化。
- 如果一个环境**物理特性已知**(known physics)，那么智能体就能知道转移模型(即使是随机的)并且可以在规划路径时使用它。如果**物理特性未知**，智能体需要有意识的(deliberately)采取行动来学习未知的动态规律(unknown dynamics)。

> **Transition model**（转移模型）通常指一种用于描述系统在不同状态之间的转移规律的模型。这种模型在许多任务中都有应用，如：强化学习、马尔可夫决策过程（MDP）等。  
> 在强化学习中，转移模型描述了一个智能体在环境中采取某个动作后，环境状态如何发生转移的规律。转移模型通常以概率形式表示，即给定当前状态和动作，描述下一个状态发生的概率分布。这种模型对于智能体来说是非常重要的，因为它可以帮助智能体预测在采取某个动作后可能遇到的情况，从而有助于智能体做出更好的决策。  
> 在马尔可夫决策过程中，转移模型描述了环境的马尔可夫性质，即当前状态的转移只依赖于前一个状态和采取的动作，与过去的历史无关（称为马尔可夫过程的无后效性）。这种模型对于求解马尔可夫决策过程的最优策略非常重要，因为它为算法提供了环境动态的描述，使得智能体能够利用动态信息做出最优的决策。
